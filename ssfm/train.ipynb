{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all instances of 40 with 30 in a numpy array\n",
    "def replace_40_with_30(arr):\n",
    "    arr[arr == 40] = 30\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LSTM Model\n",
    "class SleepScoringLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_prob=0.5):\n",
    "        super(SleepScoringLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_lstm, _ = self.lstm(x)\n",
    "        out = self.fc(h_lstm[:, -1, :])  # Use the output from the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for f in os.listdir('training_data'):\n",
    "    if f.split('__')[0] == 'features':\n",
    "        features.append(torch.tensor(np.load('training_data/' + f), dtype=torch.float32))\n",
    "        stem = f.split('__')[1]\n",
    "        assert os.path.exists('training_data/labels__' + stem), f\"no labels for {f}\"\n",
    "        \n",
    "        label = np.load('training_data/labels__' + stem)\n",
    "        label[label == 40] = 30 #makes all 'wake-good' become 'wake'\n",
    "        \n",
    "        labels.append(torch.tensor(label, dtype=torch.float32))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# Function to combine multiple recordings\n",
    "def combine_recordings(list_of_X_tensors, list_of_y_tensors):\n",
    "    X_combined = torch.cat(list_of_X_tensors, dim=0)\n",
    "    y_combined = torch.cat(list_of_y_tensors, dim=0)\n",
    "    return X_combined, y_combined\n",
    "\n",
    "# Combine all recordings\n",
    "X_combined, y_combined = combine_recordings(features, labels)\n",
    "\n",
    "\n",
    "# Unique labels and mapping to zero-indexed range\n",
    "unique_labels = torch.unique(y_combined).tolist()\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Apply the mapping\n",
    "y_combined = torch.tensor([label_mapping[label.item()] for label in y_combined], dtype=torch.long)\n",
    "\n",
    "# Debugging: Print unique values in y_combined\n",
    "print(\"Unique labels:\", torch.unique(y_combined))\n",
    "\n",
    "# Ensure the labels are within the expected range\n",
    "num_classes = len(unique_labels) # Set the number of classes based on your dataset\n",
    "assert y_combined.min() >= 0 and y_combined.max() < num_classes, \"Labels out of range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined data into training and validation sets\n",
    "dataset = TensorDataset(X_combined, y_combined)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 5  # Number of features\n",
    "hidden_dim = 128  # Number of hidden units in LSTM\n",
    "output_dim = num_classes  # Number of output classes (e.g., sleep state and confidence)\n",
    "num_layers = 2 # Number of LSTM layers\n",
    "dropout_prob = 0.25\n",
    "learning_rate = 0.002\n",
    "num_epochs = 40\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Create the model\n",
    "model = SleepScoringLSTM(input_dim, hidden_dim, output_dim, num_layers, dropout_prob).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.0556\n",
      "Validation Loss: 0.2031, Validation Accuracy: 93.05%\n",
      "Epoch [2/40], Loss: 0.1201\n",
      "Validation Loss: 0.1854, Validation Accuracy: 93.54%\n",
      "Epoch [3/40], Loss: 0.1058\n",
      "Validation Loss: 0.1783, Validation Accuracy: 93.76%\n",
      "Epoch [4/40], Loss: 0.0455\n",
      "Validation Loss: 0.1705, Validation Accuracy: 93.95%\n",
      "Epoch [5/40], Loss: 0.3458\n",
      "Validation Loss: 0.1654, Validation Accuracy: 94.16%\n",
      "Epoch [6/40], Loss: 0.2408\n",
      "Validation Loss: 0.1611, Validation Accuracy: 94.29%\n",
      "Epoch [7/40], Loss: 0.0166\n",
      "Validation Loss: 0.1580, Validation Accuracy: 94.37%\n",
      "Epoch [8/40], Loss: 0.1130\n",
      "Validation Loss: 0.1540, Validation Accuracy: 94.50%\n",
      "Epoch [9/40], Loss: 0.0539\n",
      "Validation Loss: 0.1523, Validation Accuracy: 94.55%\n",
      "Epoch [10/40], Loss: 0.0101\n",
      "Validation Loss: 0.1487, Validation Accuracy: 94.66%\n",
      "Epoch [11/40], Loss: 0.2024\n",
      "Validation Loss: 0.1490, Validation Accuracy: 94.64%\n",
      "Epoch [12/40], Loss: 0.1202\n",
      "Validation Loss: 0.1455, Validation Accuracy: 94.76%\n",
      "Epoch [13/40], Loss: 0.1224\n",
      "Validation Loss: 0.1443, Validation Accuracy: 94.80%\n",
      "Epoch [14/40], Loss: 0.2991\n",
      "Validation Loss: 0.1421, Validation Accuracy: 94.89%\n",
      "Epoch [15/40], Loss: 0.1183\n",
      "Validation Loss: 0.1419, Validation Accuracy: 94.87%\n",
      "Epoch [16/40], Loss: 0.3519\n",
      "Validation Loss: 0.1409, Validation Accuracy: 94.90%\n",
      "Epoch [17/40], Loss: 0.0194\n",
      "Validation Loss: 0.1416, Validation Accuracy: 94.93%\n",
      "Epoch [18/40], Loss: 0.2360\n",
      "Validation Loss: 0.1388, Validation Accuracy: 94.99%\n",
      "Epoch [19/40], Loss: 0.4033\n",
      "Validation Loss: 0.1369, Validation Accuracy: 95.06%\n",
      "Epoch [20/40], Loss: 0.1984\n",
      "Validation Loss: 0.1366, Validation Accuracy: 95.06%\n",
      "Epoch [21/40], Loss: 0.2297\n",
      "Validation Loss: 0.1355, Validation Accuracy: 95.12%\n",
      "Epoch [22/40], Loss: 0.1609\n",
      "Validation Loss: 0.1334, Validation Accuracy: 95.18%\n",
      "Epoch [23/40], Loss: 0.0351\n",
      "Validation Loss: 0.1331, Validation Accuracy: 95.17%\n",
      "Epoch [24/40], Loss: 0.1406\n",
      "Validation Loss: 0.1339, Validation Accuracy: 95.18%\n",
      "Epoch [25/40], Loss: 0.0656\n",
      "Validation Loss: 0.1316, Validation Accuracy: 95.24%\n",
      "Epoch [26/40], Loss: 0.3652\n",
      "Validation Loss: 0.1309, Validation Accuracy: 95.24%\n",
      "Epoch [27/40], Loss: 0.2266\n",
      "Validation Loss: 0.1294, Validation Accuracy: 95.29%\n",
      "Epoch [28/40], Loss: 0.1805\n",
      "Validation Loss: 0.1316, Validation Accuracy: 95.23%\n",
      "Epoch [29/40], Loss: 0.1058\n",
      "Validation Loss: 0.1293, Validation Accuracy: 95.32%\n",
      "Epoch [30/40], Loss: 0.0275\n",
      "Validation Loss: 0.1306, Validation Accuracy: 95.25%\n",
      "Epoch [31/40], Loss: 0.2425\n",
      "Validation Loss: 0.1284, Validation Accuracy: 95.37%\n",
      "Epoch [32/40], Loss: 0.0106\n",
      "Validation Loss: 0.1280, Validation Accuracy: 95.37%\n",
      "Epoch [33/40], Loss: 0.1977\n",
      "Validation Loss: 0.1294, Validation Accuracy: 95.32%\n",
      "Epoch [34/40], Loss: 0.0847\n",
      "Validation Loss: 0.1332, Validation Accuracy: 95.20%\n",
      "Epoch [35/40], Loss: 0.0541\n",
      "Validation Loss: 0.1280, Validation Accuracy: 95.35%\n",
      "Epoch [36/40], Loss: 0.1761\n",
      "Validation Loss: 0.1280, Validation Accuracy: 95.36%\n",
      "Epoch [37/40], Loss: 0.0597\n",
      "Validation Loss: 0.1262, Validation Accuracy: 95.43%\n",
      "Epoch [38/40], Loss: 0.0589\n",
      "Validation Loss: 0.1246, Validation Accuracy: 95.47%\n",
      "Epoch [39/40], Loss: 0.0842\n",
      "Validation Loss: 0.1232, Validation Accuracy: 95.52%\n",
      "Epoch [40/40], Loss: 0.0809\n",
      "Validation Loss: 0.1225, Validation Accuracy: 95.55%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Ensure outputs are of type torch.FloatTensor and labels are torch.LongTensor\n",
    "        outputs = outputs.float()\n",
    "        labels = labels.long()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # if (epoch+1) % 10 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluation on validation data\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = outputs.float()\n",
    "            labels = labels.long()\n",
    "            \n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/ssfm_v1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SleepScoringLSTM(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "model.load_state_dict(torch.load('models/ssfm_v1.pth'))  # Replace 'model.pth' with your model file\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "new_tensor = torch.tensor(np.load('training_data/features__ACR_33--swisin--NNXr12.npy'), dtype=torch.float32)\n",
    "\n",
    "# Move data to the device (GPU or CPU)\n",
    "new_sequences_tensor = new_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = {0: 'NREM',\n",
    "                 1: 'REM',\n",
    "                 2: 'Wake',\n",
    "                 3: 'Wake-Good',\n",
    "                 4: 'Transition-to-REM',\n",
    "                 5: 'Transition-to-NREM',\n",
    "                 6: 'Transition-to-Wake',\n",
    "                 7: 'Brief-Aroudal',\n",
    "                 8: 'Unsure',\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(new_sequences_tensor)\n",
    "    _, predicted_labels = torch.max(predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map predicted labels back to original labels\n",
    "predicted_labels = [state_mapping[label.item()] for label in predicted_labels]\n",
    "\n",
    "# Display predicted labels\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, len(predicted_labels)*2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'Time': t, 'State': predicted_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.to_csv('states.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
